{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tarachandaniheena/chatbot-using-python/blob/main/Chatbot_using_NLTK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmHZODYZ1Yyu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import string\n",
        "import random\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('/content/data.txt','r',errors='ignore')\n",
        "raw_doc = f.read()"
      ],
      "metadata": {
        "id": "R1-gdL-L13FZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_doc = raw_doc.lower()\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKjLe13C2YvH",
        "outputId": "aa5fbc7f-1744-4fe4-b150-74cec4a14e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens = nltk.sent_tokenize(raw_doc)\n",
        "word_tokens = nltk.word_tokenize(raw_doc)\n",
        "\n"
      ],
      "metadata": {
        "id": "HGbX93ud312q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "3d6X6Bnd4lJM",
        "outputId": "8bf7db88-be2a-478b-ff28-087995c46973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the reason given is: this article is using citations from 1970 and virtually all claims about conversational capabilities are at least ten years out of date (for example the turing test was arguably made obsolete years ago by transformer models).'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokens[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "M6iMeOLy4oic",
        "outputId": "25ad4092-a59e-4244-c6e3-fde309ba1163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'search'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing\n",
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "def LenTokens(tokens):\n",
        "  return [lemmer.lemmatize(token) for token in tokens]\n",
        "\n",
        "remove_punc_dict =  dict((ord(punct), None) for punct in string.punctuation)\n",
        "\n",
        "def LenNormalize(text):\n",
        "  return LenTokens(nltk.word_tokenize(text.lower().translate(remove_punc_dict)))\n"
      ],
      "metadata": {
        "id": "R1CCc4308lD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Greeting Functions\n",
        "greet_inputs = ['hi', 'hello','how are you']\n",
        "greet_responses = ['hey there', 'welcome']\n",
        "\n",
        "def greet(sentence):\n",
        "  for word in sentence.split():\n",
        "    if word.lower in greet_inputs:\n",
        "      return random.choice(greet_responses)"
      ],
      "metadata": {
        "id": "Ze3vfR0i_VBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Response Generation by the Bot\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "3HcmxE6CMINs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def response(user_response):\n",
        "  robo1_response = ''\n",
        "  tfidvec = TfidfVectorizer(tokenizer = LenNormalize, stop_words = 'english')\n",
        "  tfidf = tfidvec.fit_transform(sentence_tokens)\n",
        "  vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "  idx = vals.argsort()[0][-2]\n",
        "  flat = vals.flatten()\n",
        "  flat.sort()\n",
        "  req_tfidf = flat[-2]\n",
        "\n",
        "  if req_tfidf == 0:\n",
        "    robo1_response = \"I am sorry, unable to understand you\"\n",
        "    return robo1_response\n",
        "  else:\n",
        "    robo1_response = sentence_tokens[idx]\n",
        "    return robo1_response\n",
        "\n"
      ],
      "metadata": {
        "id": "ZRkRI_dBTcCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flag = True\n",
        "print(\"Hello! i am a learning bot, start typin your text to talk to me. For ending, type bye!\")\n",
        "\n",
        "while(flag==True):\n",
        "  user_response = input()\n",
        "  user_response = user_response.lower()\n",
        "\n",
        "  if user_response != 'bye':\n",
        "    if (user_response == 'thank you' or user_response=='thanks'):\n",
        "      flag = False\n",
        "      print('You are welcome')\n",
        "    else:\n",
        "      if (greet(user_response) != None):\n",
        "        print('Bot'+greet(user_response))\n",
        "      else:\n",
        "        sentence_tokens.append(user_response)\n",
        "        word_tokens = word_tokens + nltk.word_tokenize(user_response)\n",
        "        final_words = list(set(word_tokens))\n",
        "        print('Bot: ')\n",
        "        print(response(user_response))\n",
        "        sentence_tokens.remove(user_response)\n",
        "  else:\n",
        "    flag = False\n",
        "    print('Bot: Goodbye')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFpE6km6XU4S",
        "outputId": "1f36a182-7269-462c-cf9f-3086a3c06a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! i am a learning bot, start typin your text to talk to me. For ending, type bye!\n",
            "bye\n",
            "Bot: Goodbye\n"
          ]
        }
      ]
    }
  ]
}